{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbcb6cec-3e7d-4480-b778-f52d62b16d7c",
   "metadata": {},
   "source": [
    "# NLP pre-processing and Machine Learning Model construction.\n",
    "\n",
    "Here we will be using cleaned data from the Data Wrangling step to build and train our machine learning models so that when we deploy this model on a new dataset it can make the desired predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f053a1-95d5-42b2-8c73-3263ec8b33f9",
   "metadata": {},
   "source": [
    "# Initializing spark instance from a JupyterLab environment and creating spark session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93402548-2ce6-4da9-919d-c653c6b80c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 3.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import StorageLevel\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql import DataFrame\n",
    "import re\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"ML Model Building\") \\\n",
    "        .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\") \\\n",
    "        .config(\"spark.driver.memory\",\"4g\") \\\n",
    "        .config(\"spark.executor.memory\",\"5g\") \\\n",
    "        .master(\"local\") \\\n",
    "        .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756a66c2-2ef0-42b6-b4ea-d67c08aabc01",
   "metadata": {},
   "source": [
    "# Importing the cleaned dataset from mongoDB for NLP pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f777d6b0-aebd-442e-b8c5-305073a75a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|polarity|                text|\n",
      "+--------+--------------------+\n",
      "|     0.0|Hello everyone I'...|\n",
      "|     0.0|is not very excit...|\n",
      "|     0.0|Apparently my par...|\n",
      "|     0.0|Oh really It is t...|\n",
      "|     0.0|up at AM on a Sat...|\n",
      "+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 2.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mongo_ip = \"mongodb://localhost:27017/streaming.\"\n",
    "\n",
    "cleaned_df = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").option(\"uri\", mongo_ip + \"df_cleaned\").load()\n",
    "\n",
    "cleaned_df.createOrReplaceTempView(\"df_cleaned\")\n",
    "\n",
    "cleaned_df = spark.sql(\"SELECT polarity,text FROM df_cleaned;\")\n",
    "\n",
    "cleaned_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe422a0c-b2a2-438e-9996-1b220d3d6116",
   "metadata": {},
   "source": [
    "# Verifying the schema of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00b3ce83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- polarity: double (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a2bcd5-04f7-43ff-9a41-b9c0434effdd",
   "metadata": {},
   "source": [
    "# Spliting our data randomly into test, train and validation datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fa74949-c4a1-4fad-8686-fe3e581f49f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_data, validation_data, test_data) = cleaned_df.randomSplit([0.80, 0.10, 0.10], seed=5777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a5e37cf-ee7c-497a-9692-42c30291e3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1275891"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.count() # checking the number of records in the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513df41b-9ccf-4109-9cb3-70957d4495d6",
   "metadata": {},
   "source": [
    "# NLP Preprocessing\n",
    "\n",
    "NLP (Natural Language Processing) preprocessing is the series of steps that will be performed on raw natural language text data to prepare it for analysis using computational techniques. The goal of NLP preprocessing is to convert unstructured text data into a structured format that can be easily analyzed using machine learning and other statistical models.\n",
    "\n",
    "The NLP preprocessing techniques used are:\n",
    "\n",
    "- Tokenization: Breaking the text into individual words, phrases, or sentences.\n",
    "- Stopword removal: Removing common words that don't add much meaning to the text, such as \"the,\" \"and,\" and \"a.\"\n",
    "- Hashing term frequencies (HTF) is a technique used in natural language processing (NLP) to convert a text document into a numerical feature vector.\n",
    "- Inverse Document Frequency (IDF) is a measure used in natural language processing (NLP) and information retrieval to quantify the importance of a term in a collection of documents. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11b8502e-f86f-4585-ac43-1706b0f3b2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 243 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pyspark.ml.feature import (\n",
    "    StopWordsRemover,\n",
    "    Tokenizer,\n",
    "    HashingTF,\n",
    "    IDF,\n",
    ")\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Tokenizer takes the input string, converts it into lowercase and splits it by whitespace. The output will be called as bag of words.\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokenized_words\")\n",
    "\n",
    "# Removing stop words from english language since it has no effect on ML model training.\n",
    "\n",
    "stopwords_remover = StopWordsRemover(\n",
    "    inputCol=\"tokenized_words\",\n",
    "    outputCol=\"stopwords_removed\",\n",
    "    stopWords=StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    ")\n",
    "\n",
    "# Hashing term frequencies:\n",
    "\n",
    "hashing_tf = HashingTF(\n",
    "    inputCol=\"stopwords_removed\",\n",
    "    outputCol=\"term_frequency\",\n",
    ")\n",
    "\n",
    "# Inverse Document Frequency: \n",
    "\n",
    "idf = IDF(\n",
    "    inputCol=\"term_frequency\",\n",
    "    outputCol=\"features\",\n",
    "    minDocFreq=5,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3b2426-204f-4973-95fa-771b30454bcf",
   "metadata": {},
   "source": [
    "# Why we choosed logistic regression model\n",
    "\n",
    "Logistic regression has the following advantages:\n",
    "\n",
    "- Can handle sparse data\n",
    "- Fast to train\n",
    "- Weights can be interpreted\n",
    "- Positive weights will correspond to the words that are positive\n",
    "- Negative weights will correspond to the words that are negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d16c21-f151-40c3-970a-83ea59c20f74",
   "metadata": {},
   "source": [
    "# Building Logistic Regression pipeline model for sentimental analysis using NLP preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "471e3996-9316-40d1-9b13-0cc4ab142863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 3min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr = LogisticRegression(featuresCol='features',labelCol=\"polarity\")\n",
    "\n",
    "semantic_analysis_pipeline_lr = Pipeline(\n",
    "    stages=[tokenizer, stopwords_remover, hashing_tf, idf, lr]\n",
    ")\n",
    "\n",
    "semantic_analysis_model_lr = semantic_analysis_pipeline_lr.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b6efeca-8696-4bbb-9d3b-1ab1c8b731af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|polarity|                text|     tokenized_words|   stopwords_removed|      term_frequency|            features|       rawPrediction|         probability|prediction|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|     0.0|' Napa was stunni...|[', napa, was, st...|[', napa, stunnin...|(262144,[1512,431...|(262144,[1512,431...|[9.25919367953240...|[0.92261958057139...|       0.0|\n",
      "|     0.0|' and to think i ...|[', and, to, thin...|[', think, dedcic...|(262144,[19153,43...|(262144,[19153,43...|[8.32203343255971...|[0.64632398300240...|       0.0|\n",
      "|     0.0|' audition today ...|[', audition, tod...|[', audition, tod...|(262144,[31536,61...|(262144,[31536,61...|[9.19437425386289...|[0.91279185861405...|       0.0|\n",
      "|     0.0|' i want to see t...|[', i, want, to, ...|[', want, see, tb...|(262144,[8538,295...|(262144,[8538,295...|[10.5015843456354...|[0.99305651981779...|       0.0|\n",
      "|     0.0|''What hurts the ...|[''what, hurts, t...|[''what, hurts, c...|(262144,[9129,517...|(262144,[9129,517...|[8.03341637573036...|[0.50675291283742...|       0.0|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|polarity|                text|     tokenized_words|   stopwords_removed|      term_frequency|            features|       rawPrediction|         probability|prediction|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|     0.0|' aff que saaco Byee|[', aff, que, saa...|[', aff, que, saa...|(262144,[3032,164...|(262144,[3032,164...|[7.56173287247406...|[0.28522834510620...|       4.0|\n",
      "|     0.0|'Saw V' another p...|['saw, v', anothe...|['saw, v', anothe...|(262144,[85735,87...|(262144,[85735,87...|[9.26647149498280...|[0.92356100220421...|       0.0|\n",
      "|     0.0|'s knee hurts and...|['s, knee, hurts,...|['s, knee, hurts,...|(262144,[56998,79...|(262144,[56998,79...|[9.47512907602477...|[0.94832455876311...|       0.0|\n",
      "|     0.0|A I am sorry I wa...|[a, i, am, sorry,...|[sorry, thinking,...|(262144,[8538,329...|(262144,[8538,329...|[9.61207365331651...|[0.96018642473738...|       0.0|\n",
      "|     0.0|A I should have w...|[a, i, should, ha...|[warned, disgusti...|(262144,[18910,64...|(262144,[18910,64...|[8.19458386096378...|[0.58595853543891...|       0.0|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|polarity|                text|     tokenized_words|   stopwords_removed|      term_frequency|            features|       rawPrediction|         probability|prediction|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|     0.0|'The Importance o...|['the, importance...|['the, importance...|(262144,[2534,474...|(262144,[2534,474...|[8.97544851585017...|[0.87098316798735...|       0.0|\n",
      "|     0.0|A C is busted and...|[a, c, is, busted...|[c, busted, degre...|(262144,[13020,24...|(262144,[13020,24...|[8.83533549240337...|[0.83597462662817...|       0.0|\n",
      "|     0.0|A Friend Asked To...|[a, friend, asked...|[friend, asked, l...|(262144,[34374,59...|(262144,[34374,59...|[8.00581014190346...|[0.49228146730897...|       4.0|\n",
      "|     0.0|       A I'm failing|   [a, i'm, failing]|           [failing]|(262144,[170428],...|(262144,[170428],...|[8.68835077097995...|[0.79161422680849...|       0.0|\n",
      "|     0.0|A You know we bou...|[a, you, know, we...|[know, bout, kick...|(262144,[55639,79...|(262144,[55639,79...|[7.04782357716937...|[0.12491961218398...|       4.0|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 1.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trained_df_lr = semantic_analysis_model_lr.transform(training_data)\n",
    "validation_df_lr = semantic_analysis_model_lr.transform(validation_data)\n",
    "test_df_lr = semantic_analysis_model_lr.transform(test_data)\n",
    "\n",
    "trained_df_lr.show(5)\n",
    "validation_df_lr.show(5)\n",
    "test_df_lr.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883d5341-f10d-4ce9-aafb-e5388a79e5e3",
   "metadata": {},
   "source": [
    "# Logistic Regression model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37d4bcf1-7280-4c66-8ce5-df41d862537f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Data:\n",
      "Accuracy: 79.00657%\n",
      "Testing Data:\n",
      "Accuracy: 79.00044%\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"polarity\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy_val_lr = evaluator.evaluate(validation_df_lr)\n",
    "accuracy_test_lr = evaluator.evaluate(test_df_lr)\n",
    "\n",
    "print(\"Validation Data:\")\n",
    "print(f\"Accuracy: {accuracy_val_lr*100:.5f}%\")\n",
    "print(\"Testing Data:\")\n",
    "print(f\"Accuracy: {accuracy_test_lr*100:.5f}%\")\n",
    "\n",
    "# Try to do parameter grid and validation to increase the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4a47761-688b-4008-ad6e-9c52a0c669b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 4min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "final_logistic_model = semantic_analysis_pipeline_lr.fit(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ae0bcb5-3edc-4c35-a9bf-fce61a2cff9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PipelineModel_16ec05e33491"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "final_logistic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ba46a1b-83b5-4dd4-a130-52919b6919af",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_logistic_model_bkp = final_logistic_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1575fa-eb64-482d-b336-ab03239240d8",
   "metadata": {},
   "source": [
    "# Inference:\n",
    "\n",
    "With logistic regression model we got accuracy of 79% with validation dataset and 79% accuracy with test dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
