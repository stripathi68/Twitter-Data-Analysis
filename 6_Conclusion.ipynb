{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caef68a3-eb77-4472-b6d8-9896df645919",
   "metadata": {},
   "source": [
    "# Challenges faced\n",
    "\n",
    "- In this project we are dealing with unstructured data which is completely new to us.\n",
    "- Identifying a data source on which we can train our Supervised Machine Learning model.\n",
    "- Learning about NPL preprocessing and Text Analytics where we have used regular expressions.\n",
    "- Integrating mongoDB and Kafka with our Juypter Notebook.\n",
    "- Learning about how to use Spark UI including DAG (Directed Acyclic Graph) for debugging issues.\n",
    "- Tried to implement other ML models such as Decision Tree Classifier, SVM, Random Forest Classifier but we faced issue with respect to the executor driver memory and even when we increased to memory size to 50gb was there. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef5205d-a6ae-4277-a136-747c0be30c18",
   "metadata": {},
   "source": [
    "# Contributions of team members\n",
    "\n",
    "- Akshay Ramesh: Responsible for creating the project architecture, starting from identifying the project topic to figuring out how to establish connection to mongo DB and Kafka implementation. Also, participated in the building of Machine Learning Model Pipelines and ML models.\n",
    "\n",
    "- Pranjal Singh: Played a pivotal role in the project's success by actively collaborating with the team on various aspects, including data wrangling, ML model development, and identifying valuable data sources. Demonstrated strong teamwork skills and contributed effectively to streamline data processes, resulting in improved project outcomes.\n",
    "\n",
    "- Surabhi Tripathi: Actively collaborated with my colleagues throughout the entire project lifecycle, from identifying relevant topics and acquiring data to performing data wrangling, building machine learning models, identifying data sources, and debugging code. By working closely with the team and contributing to each stage of the project, played an instrumental role in ensuring the project's success."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45c7a59-11ed-47d3-8290-c3beac79af3e",
   "metadata": {},
   "source": [
    "# Final Note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54b45c8-0e96-4f2d-bb05-04ac5e9bdf05",
   "metadata": {},
   "source": [
    "We have tried our best to make sure that this project simulates the Real-Time scenarios. Also, we have used all the things we learned in the class such as NoSQL DB for storage, PySPark for Analysis, SparkML for making predictions and finally storaging back our final results into NoSQL DB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deed5a5-07c2-478e-a1b0-25a173104f26",
   "metadata": {},
   "source": [
    "This archicture can be used to perform sentimental analysis on other data source either streaming data sources like Reddit or on historical data source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630c84ae-262b-4100-9464-b5f63d3801a5",
   "metadata": {},
   "source": [
    "# References:\n",
    "\n",
    "- https://developer.hpe.com/blog/streaming-ml-pipeline-for-sentiment-analysis-using-apache-apis-kafka-spark-and-drill-part-2/\n",
    "- https://spark.apache.org/docs/latest/ml-classification-regression.html\n",
    "- https://spark.apache.org/docs/latest/ml-clustering.html\n",
    "- https://chat.openai.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
