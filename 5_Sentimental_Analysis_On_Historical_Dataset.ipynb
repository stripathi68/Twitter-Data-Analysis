{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fd6eb1f-23a8-4b8a-b0fb-1f2135550a13",
   "metadata": {},
   "source": [
    "# Sentimental Analysis on historical data.\n",
    "\n",
    "Data Source: https://www.kaggle.com/datasets/bwandowando/ukraine-russian-crisis-twitter-dataset-1-2-m-rows\n",
    "\n",
    "This data is extracted from the twitter by a user who has collected live twitter data on the ongoing Russia-Ukrain Crisis. We have taken only few .csv files containing total of 3M rows for our Sentimental Analysis.\n",
    "\n",
    "The data is stored in mongoDB and not in the local storage and we will be performing Data Wrangling, NLP Preprocessing, and finally applying our logistic regression model to predict the sentiment of the users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0339152b-396b-4239-b2ca-f68fdcf129ee",
   "metadata": {},
   "source": [
    "# Our final Logistic Regression model which will be deployed on our historical dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dfb790d4-cfa9-4704-9bb2-e383f22198c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineModel_16ec05e33491"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_logistic_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088ed254-c94c-402e-a845-4233dbd1bfaf",
   "metadata": {},
   "source": [
    "# Importing our data from mongoDB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0ccfd269-c903-4798-b58e-dd646f0f2864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 5.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mongo_ip = \"mongodb://localhost:27017/streaming.\"\n",
    "\n",
    "df_war = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").option(\"uri\", mongo_ip + \"Ukraine_Russia_Crisis\").load()\n",
    "\n",
    "df_war.createOrReplaceTempView(\"df_war_cleaned\")\n",
    "\n",
    "df_war = spark.sql(\"select text from df_war_cleaned;\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f0df0bd8-57b1-484c-9f87-716416b43fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_war.printSchema() # checking the schema of the imported dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be1728d-3d94-448f-8444-5900c4829424",
   "metadata": {},
   "source": [
    "# Creating a function and UDF to perform data wrangling where we will be removing unwanted characters otherwise it will impact the performance of our regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8bea2f76-cd93-4fc4-8859-66d99aef991e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import html\n",
    "\n",
    "@f.udf\n",
    "def html_unescape(s: str):\n",
    "    if isinstance(s, str):\n",
    "        return html.unescape(s)\n",
    "    return s\n",
    "\n",
    "user_regex = r\"(@\\w{1,15})\"\n",
    "hashtag_regex = r\"(#\\w{1,})\"\n",
    "url_regex = r\"((https?|ftp|file):\\/{2,3})+([-\\w+&@#/%=~|$?!:,.]*)|(www.)+([-\\w+&@#/%=~|$?!:,.]*)\"\n",
    "email_regex = r\"[\\w.-]+@[\\w.-]+\\.[a-zA-Z]{1,}\"\n",
    "\n",
    "def clean_data(df):\n",
    "    df = (\n",
    "        df\n",
    "        .withColumn(\"text\", f.regexp_replace(f.col(\"text\"), url_regex, \"\")) # replacing urls with empty string\n",
    "        .withColumn(\"text\", f.regexp_replace(f.col(\"text\"), email_regex, \"\")) # replacing email with empty strings\n",
    "        .withColumn(\"text\", f.regexp_replace(f.col(\"text\"), user_regex, \"\")) # replacing @<user_name> with empty string\n",
    "        .withColumn(\"text\", f.regexp_replace(f.col(\"text\"), \"#\", \" \")) # replacing '#' with space\n",
    "        .withColumn(\"text\", html_unescape(f.col(\"text\")))  # removing html using UDF \n",
    "        .withColumn(\"text\", f.regexp_replace(f.col(\"text\"), \"[^a-zA-Z']\", \" \")) # remove all numbers\n",
    "        .withColumn(\"text\", f.regexp_replace(f.col(\"text\"), r'\\s{1,}', ' ')) # replace consecutive spaces (1 to any number) with a single space\n",
    "        .withColumn(\"text\", f.trim(f.col(\"text\"))) # removing leading and trailing whitespaces\n",
    "        .filter(\"text != ''\") # removing empty strings\n",
    "    )\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2303393-a94c-481f-81ce-56dd3e650c04",
   "metadata": {},
   "source": [
    "# Applying cleaning logic on our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3149230-d213-441f-9504-c0cc00056163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 72.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_war = clean_data(df_war)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfcd68c-2bd6-433c-9b47-f5508c582b25",
   "metadata": {},
   "source": [
    "# Apply the logistic regression model to the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9875fc0f-edb7-4e9f-8d40-67a6848ee706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 92.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "\n",
    "predictions = final_logistic_model.transform(df_war)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d751e062-e9de-40ce-b60d-361363e1d5e3",
   "metadata": {},
   "source": [
    "# Selecting desired columns for our predictions dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d057b9d7-91fa-40c0-bdf7-8f2464236ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 31 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions.createOrReplaceTempView(\"prediction_sql\")\n",
    "\n",
    "ukraine_war_df= spark.sql(\"select prediction,text from prediction_sql;\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b226c-53d2-4ae7-ad32-9ecd2be62768",
   "metadata": {},
   "source": [
    "# Identifying what type of sentiments the users have based ML model predictions on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b8e2580e-d1d2-4384-8998-bc09a64a4579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|prediction| count|\n",
      "+----------+------+\n",
      "|       0.0|910194|\n",
      "|       4.0|533729|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ukraine_war_df.groupBy(\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a529e1e-f10f-4cb6-8135-2e0999e95238",
   "metadata": {},
   "source": [
    "# Business Conclusion:\n",
    "\n",
    "Based on the 3M rows of twitter data we have analyzed we can say that people are having negative sentiment on the ongoing Russia-Ukraine crisis. This prediction is based on our logistic regression model which is having accuracy of 79%. Moreover, our model accuracy is highly dependent on Sentiment140 dataset which we used to train our model to perform supervised machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b68c351-c000-45c6-b78b-9e8aaba448b3",
   "metadata": {},
   "source": [
    "# Storing the sentimental data in the mongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7e4cbdef-c302-4fcb-955d-61cec25a0fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 93.8 ms\n",
      "Wall time: 7min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ukraine_war_df.write.format(\"com.mongodb.spark.sql.DefaultSource\") \\\n",
    "  .option(\"uri\", mongo_ip + \"Ukraine_Crisis_Sentement\") \\\n",
    "  .mode(\"append\") \\\n",
    "  .save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9e0e5cc3-46be-48e3-b6d4-1697f9af8198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 6min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ukraine_war_df.write.format(\"com.mongodb.spark.sql.DefaultSource\") \\\n",
    "  .option(\"uri\", mongo_ip + \"Ukraine_Crisis_Sentement_demo\") \\\n",
    "  .mode(\"append\") \\\n",
    "  .save()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
